{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "from torch import nn\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.colors import Normalize\n",
    "import torch\n",
    "from skimage.color import rgb2gray\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "path=\"./cine_seg.npz\" # input the path of cine_seg.npz in your environment\n",
    "data=np.load(path,allow_pickle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imgshow(im, cmap=None, rgb_axis=None, dpi=100, figsize=(6.4, 4.8)):\n",
    "    if isinstance(im, torch.Tensor):\n",
    "        im = im.to('cpu').detach().cpu().numpy()\n",
    "    if rgb_axis is not None:\n",
    "        im = np.moveaxis(im, rgb_axis, -1)\n",
    "        im = rgb2gray(im)\n",
    "\n",
    "    plt.figure(dpi=dpi, figsize=figsize)\n",
    "    norm_obj = Normalize(vmin=im.min(), vmax=im.max())\n",
    "    plt.imshow(im, norm=norm_obj, cmap=cmap)\n",
    "    plt.colorbar()\n",
    "    plt.show()\n",
    "    plt.close('all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把list转换成array\n",
    "data_new=[]\n",
    "for x in data.files:\n",
    "    data_new.append(data[x])\n",
    "data_new=np.array(data_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算data_new中的label有多少全是0并且删除，data_new的shape为(1798,2,256,256),label是data_new[:,1]\n",
    "count=0\n",
    "print(data_new.shape)\n",
    "for i in range(data_new.shape[0]):\n",
    "    if np.sum(data_new[i,1])==0:\n",
    "        count+=1\n",
    "print(count)\n",
    "data_new=data_new[data_new[:,1].sum(axis=(1,2))!=0]\n",
    "print(data_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算data_new中的label的类别数量小于等于3个的并且删除，data_new的shape为(1798,2,256,256),label是data_new[:,1]\n",
    "count=0\n",
    "print(data_new.shape)\n",
    "for i in range(data_new.shape[0]):\n",
    "    if len(np.unique(data_new[i,1]))<=3:\n",
    "        count+=1\n",
    "print(count)\n",
    "data_new=data_new[np.array([len(np.unique(x))>3 for x in data_new[:,1]])]\n",
    "print(data_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_samples = len(data_new)\n",
    "num_train = int(total_samples * 4 / 7)\n",
    "num_val = int(total_samples * 1 / 7)\n",
    "num_test = total_samples - num_train - num_val\n",
    "print(total_samples,num_train, num_val, num_test)\n",
    "#为了让训练时每个batch size一致，取整\n",
    "train_input = data_new[:850][:,0]\n",
    "val_input = data_new[850:1100][:,0]\n",
    "test_input = data_new[1100:][:,0]\n",
    "train_output = data_new[:850][:,1]\n",
    "val_output = data_new[850:1100][:,1]\n",
    "test_output = data_new[1100:][:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将0,85,170,255转换为0,1,2,3\n",
    "train_output[train_output == 85] = 1\n",
    "train_output[train_output == 170] = 2\n",
    "train_output[train_output == 255] = 3\n",
    "val_output[val_output == 85] = 1\n",
    "val_output[val_output == 170] = 2\n",
    "val_output[val_output == 255] = 3\n",
    "test_output[test_output == 85] = 1\n",
    "test_output[test_output == 170] = 2\n",
    "test_output[test_output == 255] = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#加入数据增强\n",
    "is_aug = False\n",
    "if is_aug:\n",
    "    #旋转90度\n",
    "    def rotate90(img):\n",
    "        return np.rot90(img, k=1, axes=(0, 1))\n",
    "    #翻转\n",
    "    def flip(img):\n",
    "        return np.flip(img, axis=1)\n",
    "    #应用到训练集，验证集和测试集不需要增强\n",
    "    train_input_aug = np.concatenate([train_input, np.array([rotate90(x) for x in train_input])])\n",
    "    train_output_aug = np.concatenate([train_output, train_output])\n",
    "    train_input_aug = np.concatenate([train_input_aug, np.array([flip(x) for x in train_input])])\n",
    "    train_output_aug = np.concatenate([train_output_aug, train_output])\n",
    "    train_input = train_input_aug\n",
    "    train_output = train_output_aug\n",
    "print(train_input.shape, train_output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#把numpy数组转变成torch类型，构建loader\n",
    "train_data = torch.from_numpy(train_input).float()\n",
    "train_label = torch.from_numpy(train_output).float()\n",
    "val_data = torch.from_numpy(val_input).float()\n",
    "val_label = torch.from_numpy(val_output).float()\n",
    "test_data = torch.from_numpy(test_input) .float()\n",
    "test_label = torch.from_numpy(test_output) .float()\n",
    "BZ=10\n",
    "train = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_data, train_label), batch_size=BZ, shuffle=True)\n",
    "val = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(val_data, val_label), batch_size=BZ, shuffle=True)\n",
    "test = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_data, test_label), batch_size=BZ, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DoubleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: [B, C_in, H, W]\n",
    "        out: [B, C_out, H, W]\n",
    "        \"\"\"\n",
    "        out = self.layers(x)\n",
    "        return out\n",
    "\n",
    "class Down(nn.Module):\n",
    "    \"\"\"Downscaling with maxpool then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.maxpool_conv = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            DoubleConv(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):        \n",
    "        return self.maxpool_conv(x)\n",
    "class Up(nn.Module):\n",
    "    \"\"\"Upscaling then double conv\"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()        \n",
    "        \n",
    "        self.up = nn.ConvTranspose2d(in_channels, in_channels // 2, kernel_size=2, stride=2)\n",
    "        self.conv = DoubleConv(in_channels, out_channels)\n",
    "        \n",
    "\n",
    "    def forward(self, x1, x2):        \n",
    "        \n",
    "        \n",
    "        x1 = self.up(x1)\n",
    "        H1, W1 = x1.shape[2:]\n",
    "        H2, W2 = x2.shape[2:]\n",
    "        \n",
    "        x1 = F.pad(x1, [\n",
    "            (W2-W1) // 2, # left\n",
    "            (W2-W1) // 2, # right\n",
    "            (H2-H1) // 2, # top\n",
    "            (H2-H1) // 2  # bottom\n",
    "            ])\n",
    "\n",
    "        x = torch.cat([x2, x1], dim=1)\n",
    "        out = self.conv(x)\n",
    "        \n",
    "        return out\n",
    "class UNet(nn.Module):\n",
    "    def __init__(self, n_channels, n_classes, C_base=64):\n",
    "        super(UNet, self).__init__()\n",
    "        self.n_channels = n_channels\n",
    "        self.n_classes = n_classes\n",
    "\n",
    "        self.in_conv = DoubleConv(n_channels, C_base)\n",
    "\n",
    "        self.down1 = Down(C_base, 2 * C_base)\n",
    "        self.down2 = Down(2 * C_base, 4 * C_base)\n",
    "        self.down3 = Down(4 * C_base, 8 * C_base)\n",
    "        self.down4 = Down(8 * C_base, 16 * C_base)\n",
    "        self.up1 = Up(16 * C_base, 8 * C_base)\n",
    "        self.up2 = Up(8 * C_base, 4 * C_base)\n",
    "        self.up3 = Up(4 * C_base, 2 * C_base)\n",
    "        self.up4 = Up(2 * C_base, C_base)\n",
    "        self.out_projection = nn.Conv2d(C_base, n_classes, kernel_size=1)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        :param x: [B, n_channels, H, W]\n",
    "        :return [B, n_classes, H, W]\n",
    "        \"\"\" \n",
    "        x1 = self.in_conv(x)\n",
    "        \n",
    "        x2 = self.down1(x1)\n",
    "        x3 = self.down2(x2)\n",
    "        x4 = self.down3(x3)\n",
    "        x5 = self.down4(x4)\n",
    "\n",
    "        x = self.up1(x5, x4)\n",
    "        x = self.up2(x, x3)\n",
    "        x = self.up3(x, x2)\n",
    "        x = self.up4(x, x1)\n",
    "        pred = self.out_projection(x)        \n",
    "        \n",
    "        return pred\n",
    "\n",
    "#test\n",
    "net = UNet(n_channels=1, n_classes=4)\n",
    "x = torch.randn(5, 1, 256, 256)\n",
    "out = net(x)\n",
    "assert (5, 4, 256, 256) == out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixel_wise_cross_entropy_loss_weighted(logits, labels, class_weights):\n",
    "    '''\n",
    "    Custom weighted cross entropy loss for pixel-wise class weighting using class index labels\n",
    "    '''\n",
    "    n_class = len(class_weights)\n",
    "    class_weights = torch.tensor(class_weights, dtype=torch.float32, device=logits.device)\n",
    "    return nn.CrossEntropyLoss(weight=class_weights)(logits, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = UNet(n_channels=1, n_classes=4) .to(device)\n",
    "criterion = pixel_wise_cross_entropy_loss_weighted\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "num_epochs=200\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "train_cur_loss = 0\n",
    "val_cur_loss = 0\n",
    "for epoch in range(num_epochs):\n",
    "    for data in train:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        inputs=inputs.reshape(BZ,1,256,256)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.long(),[0.1,0.3,0.3,0.3])\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_cur_loss += loss.item()\n",
    "    train_losses.append(train_cur_loss / len(train))\n",
    "    train_cur_loss = 0\n",
    "    for data in val:\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        inputs=inputs.reshape(BZ,1,256,256)\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels.long(),[0.1,0.3,0.3,0.3])\n",
    "        val_cur_loss += loss.item()\n",
    "    val_losses.append(val_cur_loss / len(val))\n",
    "    val_cur_loss = 0\n",
    "    print (f'Epoch {epoch+1}/{num_epochs}, Train Loss: {train_losses[-1]}, Val Loss: {val_losses[-1]}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#将模型和两个loss保存\n",
    "#name=\"(c)model200epslr001\"\n",
    "name=\"test\"\n",
    "torch.save(model.state_dict(), \".\\\\savedata\\\\\"+name+\".pth\")\n",
    "np.savez(\".\\\\savedata\\\\\"+name+\".npz\",train_losses=train_losses,val_losses=val_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 绘制训练损失和验证损失\n",
    "length_of_data_loss = len(train_losses)\n",
    "x_ticks_loss = [i for i in range(1, length_of_data_loss + 1)]\n",
    "fig, ax1 = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "ax1.plot(x_ticks_loss, train_losses, label='Train Loss', marker='o')\n",
    "ax1.plot(x_ticks_loss, val_losses, label='Validation Loss', marker='o')\n",
    "\n",
    "# 添加竖线\n",
    "for i in range(1, length_of_data_loss + 2, 1):\n",
    "    ax1.axvline(x=i-1, color='gray', linestyle='--', linewidth=0.5)\n",
    "\n",
    "# 添加文本注释\n",
    "# for i in range(length_of_data_loss):\n",
    "#     if (i) % 1 == 0 or i == length_of_data_loss - 1 or i == 0:\n",
    "#         ax1.text(x_ticks_loss[i], train_losses[i], f'{train_losses[i]:.6f}', ha='center', va='bottom', fontsize=12)\n",
    "#         ax1.text(x_ticks_loss[i], val_losses[i], f'{val_losses[i]:.6f}', ha='center', va='bottom', fontsize=12)\n",
    "\n",
    "ax1.set_xlabel('Epoch')\n",
    "ax1.set_ylabel('Loss')\n",
    "ax1.set_title('Training and Validation Loss')\n",
    "ax1.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#展示某张图片的预测结果\n",
    "# input=val_data[101].to(device)\n",
    "# label=val_label[101].to(device)\n",
    "# output=model(input.reshape(1,1,256,256))\n",
    "# _, predicted_indices = torch.max(output, 1)  # 使用torch.max获取类别索引，第一个维度是类别维\n",
    "\n",
    "# # 将类别索引映射到灰度值\n",
    "# # 创建一个映射数组\n",
    "# mapping = torch.tensor([0, 85, 170, 255], dtype=torch.uint8).to(predicted_indices.device)\n",
    "# # 使用映射数组将类别索引转换为相应的灰度值\n",
    "# final_image = mapping[predicted_indices]\n",
    "# imgshow(final_image[0])\n",
    "# imgshow(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#展示某张图片的原始图片\n",
    "# print(val_label[101].shape)\n",
    "# print(np.unique(val_label[101]))\n",
    "# #输出每个类别的像素数量\n",
    "# for i in range(4):\n",
    "#     a=val_label[101]==i\n",
    "#     print(sum(sum(a)))\n",
    "# imgshow(val_data[101])\n",
    "# imgshow(val_label[101])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#计算验证集上的Dice系数\n",
    "def dice_coefficient(pred, true, label):\n",
    "    index={85:1,170:2,255:3}\n",
    "    # 获取指定标签的二值图像\n",
    "    pred_binary = (pred == label)\n",
    "    true_binary = (true == index[label])\n",
    "    #显示二值图像\n",
    "    \n",
    "    # 计算交集\n",
    "    intersection = np.sum(pred_binary & true_binary)\n",
    "    # 计算每个图像的目标区域像素数量\n",
    "    pred_sum = np.sum(pred_binary)\n",
    "    true_sum = np.sum(true_binary)\n",
    "    \n",
    "    # 计算Dice系数\n",
    "    if pred_sum + true_sum == 0:\n",
    "        return 1.0  # 如果预测和真实图像中都没有这个标签，认为Dice系数为1\n",
    "    dice = (2. * intersection) / (pred_sum + true_sum)\n",
    "    \n",
    "    return dice\n",
    "test_data=val_data.to(device)\n",
    "test_label=val_label.to(device)\n",
    "model = model.to(device)\n",
    "total_rv = []\n",
    "total_myo = []\n",
    "total_lv = []\n",
    "cnt_rv=cnt_myo=cnt_lv=0\n",
    "min_rv=min_myo=min_lv=1\n",
    "index_min_rv=index_min_myo=index_min_lv=0\n",
    "for i in range(len(val_data)):\n",
    "    input=val_data[i].to(device)\n",
    "    label=val_label[i].to(device)\n",
    "    output=model(input.reshape(1,1,256,256))\n",
    "    _, predicted_indices = torch.max(output, 1)  # 使用torch.max获取类别索引，第一个维度是类别维\n",
    "\n",
    "    # 将类别索引映射到灰度值\n",
    "    # 创建一个映射数组\n",
    "    mapping = torch.tensor([0, 85, 170, 255], dtype=torch.uint8).to(predicted_indices.device)\n",
    "    # 使用映射数组将类别索引转换为相应的灰度值\n",
    "    final_image = mapping[predicted_indices]\n",
    "    pred=final_image.reshape(256,256).cpu().numpy()\n",
    "    true=label.cpu().numpy()\n",
    "    dice_rv = dice_coefficient(pred, true, 85)\n",
    "    dice_myo = dice_coefficient(pred, true, 170)\n",
    "    dice_lv = dice_coefficient(pred, true, 255)\n",
    "    if dice_rv<min_rv:\n",
    "        min_rv=dice_rv\n",
    "        index_min_rv=i\n",
    "    if dice_myo<min_myo:\n",
    "        min_myo=dice_myo\n",
    "        index_min_myo=i\n",
    "    if dice_lv<min_lv:\n",
    "        min_lv=dice_lv\n",
    "        index_min_lv=i\n",
    "    if dice_rv!=0:\n",
    "        total_rv .append(dice_rv)\n",
    "        cnt_rv+=1\n",
    "    if dice_myo!=0:\n",
    "        total_myo.append(dice_myo)\n",
    "        cnt_myo+=1\n",
    "    if dice_lv!=0:\n",
    "        total_lv.append(dice_lv)\n",
    "        cnt_lv+=1\n",
    "total_rv = np.array(total_rv)\n",
    "total_myo = np.array(total_myo)\n",
    "total_lv = np.array(total_lv)\n",
    "#计算平均Dice系数\n",
    "mean_rv = np.mean(total_rv)\n",
    "mean_myo = np.mean(total_myo)\n",
    "mean_lv = np.mean(total_lv)\n",
    "#计算标准差\n",
    "std_rv = np.std(total_rv)\n",
    "std_myo = np.std(total_myo)\n",
    "std_lv = np.std(total_lv)\n",
    "print(f'RV Dice系数平均值: {mean_rv:.4f}, 标准差: {std_rv:.4f}')\n",
    "print(f'MYO Dice系数平均值: {mean_myo:.4f}, 标准差: {std_myo:.4f}')\n",
    "print(f'LV Dice系数平均值: {mean_lv:.4f}, 标准差: {std_lv:.4f}')\n",
    "# print(min_rv,index_min_rv)\n",
    "# print(min_myo,index_min_myo)\n",
    "# print(min_lv,index_min_lv)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
